{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "from qrytool import load_data_into_dataframe, insert_dataframe_into_table\n",
    "from geopy.distance import geodesic\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import os\n",
    "import ray\n",
    "from tqdm.notebook import tqdm\n",
    "from geotool import replace_address_sido\n",
    "\n",
    "\n",
    "def calculate_min_distance(row, df_subway):\n",
    "    lat1, lon1 = row['위도'], row['경도']\n",
    "    min_distance = float('inf')\n",
    "    nearest_station = None\n",
    "    row_region = row['지역'].split()[0]\n",
    "\n",
    "    # Filter df_subway by matching the first word of '지역' column\n",
    "    filtered_df_subway = df_subway[df_subway['지역'].apply(lambda x: x.split()[0]) == row_region]\n",
    "\n",
    "    if not filtered_df_subway.empty:\n",
    "        for _, subway_row in filtered_df_subway.iterrows():\n",
    "            lat2, lon2 = subway_row['lati'], subway_row['longi']\n",
    "            distance = geodesic((lat1, lon1), (lat2, lon2)).meters\n",
    "\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                nearest_station = subway_row\n",
    "    else:\n",
    "        # If no matching rows are found\n",
    "        return {\n",
    "            'index': row['index'],\n",
    "            '최단지하철역': '없음',\n",
    "            '역과거리': 10000000,\n",
    "            '역사명': '없음',\n",
    "            '근접노선수': 0,\n",
    "            '역lati': 51.5074,\n",
    "            '역longi': 0.1278,\n",
    "            '도보거리': False\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        'index': row['index'],\n",
    "        '최단지하철역': nearest_station['역사명'],\n",
    "        '역과거리': min_distance,\n",
    "        '역사명': nearest_station['역사명'],\n",
    "        '근접노선수': nearest_station['근접노선수'],\n",
    "        '역lati': nearest_station['lati'],\n",
    "        '역longi': nearest_station['longi'],\n",
    "        '도보거리': min_distance <= 500\n",
    "    }\n",
    "\n",
    "\n",
    "def prepare_subway_data(df_subway):\n",
    "    def get_region(address):\n",
    "        region = replace_address_sido(address)\n",
    "        return ' '.join(region.split()[:2])\n",
    "\n",
    "    df_subway['지역'] = df_subway.apply(\n",
    "        lambda row: get_region('대구시 ' + row['역사도로명주소']) if row['운영기관명'] == '대구교통공사' else get_region(row['역사도로명주소']),\n",
    "        axis=1\n",
    "    )\n",
    "    return df_subway\n",
    "\n",
    "\n",
    "def process_region_naver_cortar_addr(dongne):\n",
    "    words = dongne.split()\n",
    "    if len(words) > 0 and words[0].endswith('시'):\n",
    "        return ' '.join([words[0][:-1]] + words[1:2])\n",
    "    else:\n",
    "        region = replace_address_sido(dongne)\n",
    "        return ' '.join(region.split()[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "qry = \"\"\"\n",
    "SELECT\n",
    "    complex_name 아파트명,\n",
    "    cortar_address 동네,\n",
    "    real_estate_type_name 건물종류,\n",
    "    latitude 위도,\n",
    "    longitude 경도,\n",
    "    CAST(REPLACE(pyeong_content, '공급 ', '') AS DECIMAL) AS 면적,\n",
    "    floor 층,\n",
    "    formatted_trade_year_month 거래년월일,\n",
    "    total_household_count 가구수,\n",
    "    total_building_count 동수,\n",
    "    use_approve_ymd 사용승인년월일,\n",
    "    deal_price 거래가\n",
    "FROM train_base_data;\n",
    "\"\"\"\n",
    "\n",
    "df = load_data_into_dataframe(qry)\n",
    "\n",
    "df['거래년월일'] = pd.to_datetime(df['거래년월일'], errors='coerce')\n",
    "df['사용승인년월일'] = pd.to_datetime(df['사용승인년월일'], errors='coerce')\n",
    "\n",
    "# Process '동네' column\n",
    "df['지역'] = df['동네'].apply(process_region_naver_cortar_addr)\n",
    "\n",
    "\n",
    "# 오늘 날짜를 기준으로 건물의 나이 계산\n",
    "today = datetime.now()\n",
    "df['나이'] = (today - df['사용승인년월일']).dt.days / 365.25  # 일수를 년도로 변환\n",
    "\n",
    "# 인덱스 추가 (결과 병합을 위해)\n",
    "df.reset_index(inplace=True)\n",
    "df = df[~df['지역'].str.contains('제주')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지하철 거리 연관성 학습 데이터 생성\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존 학습된 데이터가 있을 경우 다시 계산하지 않고 계산하여 저장한 파일을 로드하여 진행하면 됨.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21f9d4147aa41cf86d94bf25548874e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/10181332 [00:00<?, ?it/s]   0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 순차적으로 처리 실행\n",
    "batch_size = 300\n",
    "num_cores = 23\n",
    "# 결과 저장할 CSV 파일 초기화\n",
    "output_file = 'output.csv'\n",
    "\n",
    "\n",
    "if not ray.is_initialized():\n",
    "    ray.init(num_cpus=23)\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def process_batch(batch, df_subway):\n",
    "    results = []\n",
    "    for _, row in batch.iterrows():\n",
    "        result = calculate_min_distance(row, df_subway)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "# 데이터 로드\n",
    "file_path = \"./전국_도시철도역사정보_좌표포함.xlsx\"\n",
    "df_subway = pd.read_excel(file_path)\n",
    "df_subway = prepare_subway_data(df_subway)\n",
    "\n",
    "# 처리된 인덱스 추적\n",
    "completed_indices = set()\n",
    "if os.path.exists(output_file):\n",
    "    processed_results = pd.read_csv(output_file)\n",
    "    completed_indices = set(processed_results['index'])\n",
    "else:\n",
    "    # 결과 파일에 헤더 작성\n",
    "    pd.DataFrame(columns=['index', '최단지하철역', '역과거리', '역사명', '근접노선수', '역lati', '역longi', '도보거리']).to_csv(output_file, index=False)\n",
    "\n",
    "# 처리되지 않은 행들만 선택\n",
    "remaining_rows = df[~df['index'].isin(completed_indices)]\n",
    "total_rows = len(remaining_rows)\n",
    "\n",
    "# Custom bar format for tqdm\n",
    "bar_format = '{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}] {percentage:3.0f}%'\n",
    "\n",
    "# Process the data in batches\n",
    "with tqdm(total=total_rows, desc=\"Processing rows\", bar_format=bar_format) as pbar:\n",
    "    futures = []\n",
    "    start_index = 0\n",
    "\n",
    "    while start_index < total_rows or futures:\n",
    "        # Submit tasks until the core limit is reached\n",
    "        while len(futures) < num_cores and start_index < total_rows:\n",
    "            batch = remaining_rows.iloc[start_index:start_index + batch_size]\n",
    "            future = process_batch.remote(batch, df_subway)\n",
    "            futures.append(future)\n",
    "            start_index += batch_size\n",
    "\n",
    "        # Wait for the first available future to complete\n",
    "        if futures:\n",
    "            ready_futures, remaining_futures = ray.wait(futures, num_returns=1)\n",
    "            futures = remaining_futures\n",
    "\n",
    "            for ready_future in ready_futures:\n",
    "                result = ray.get(ready_future)\n",
    "                result_df = pd.DataFrame(result)\n",
    "                result_df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "                pbar.update(batch_size)\n",
    "\n",
    "# Shut down Ray\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3198134/2703775935.py:5: DtypeWarning: Columns (0,2,4,5,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  processed_results = pd.read_csv(output_file, header=None, names=['index', '최단지하철역', '역과거리', '역사명', '근접노선수', '역lati', '역longi', '도보거리'])\n"
     ]
    }
   ],
   "source": [
    "output_file = 'output.csv'\n",
    "\n",
    "# 결과 파일에서 최종 DataFrame 로드 및 원래 DataFrame과 병합\n",
    "# processed_results = pd.read_csv(output_file, header=None, names=['index', '최단지하철역', '역과거리', '역사명', '근접노선수', '역lati', '역longi', '도보거리'])\n",
    "processed_results = pd.read_csv(output_file, header=None, names=['index', '최단지하철역', '역과거리', '역사명', '근접노선수', '역lati', '역longi', '도보거리'])\n",
    "df_final = df.merge(processed_results, on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10181332, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10115797, 22)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>아파트명</th>\n",
       "      <th>동네</th>\n",
       "      <th>건물종류</th>\n",
       "      <th>위도</th>\n",
       "      <th>경도</th>\n",
       "      <th>면적</th>\n",
       "      <th>층</th>\n",
       "      <th>거래년월일</th>\n",
       "      <th>가구수</th>\n",
       "      <th>동수</th>\n",
       "      <th>사용승인년월일</th>\n",
       "      <th>거래가</th>\n",
       "      <th>지역</th>\n",
       "      <th>나이</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>꿈의숲코오롱하늘채</td>\n",
       "      <td>서울시 성북구 장위동</td>\n",
       "      <td>아파트</td>\n",
       "      <td>37.619397</td>\n",
       "      <td>127.04663</td>\n",
       "      <td>115.07</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>513</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-10-30</td>\n",
       "      <td>100800.0</td>\n",
       "      <td>서울 성북구</td>\n",
       "      <td>6.699521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>꿈의숲코오롱하늘채</td>\n",
       "      <td>서울시 성북구 장위동</td>\n",
       "      <td>아파트</td>\n",
       "      <td>37.619397</td>\n",
       "      <td>127.04663</td>\n",
       "      <td>115.07</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2024-04-20</td>\n",
       "      <td>513</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-10-30</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>서울 성북구</td>\n",
       "      <td>6.699521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>꿈의숲코오롱하늘채</td>\n",
       "      <td>서울시 성북구 장위동</td>\n",
       "      <td>아파트</td>\n",
       "      <td>37.619397</td>\n",
       "      <td>127.04663</td>\n",
       "      <td>115.07</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2024-02-25</td>\n",
       "      <td>513</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-10-30</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>서울 성북구</td>\n",
       "      <td>6.699521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>꿈의숲코오롱하늘채</td>\n",
       "      <td>서울시 성북구 장위동</td>\n",
       "      <td>아파트</td>\n",
       "      <td>37.619397</td>\n",
       "      <td>127.04663</td>\n",
       "      <td>115.07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>513</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-10-30</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>서울 성북구</td>\n",
       "      <td>6.699521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>꿈의숲코오롱하늘채</td>\n",
       "      <td>서울시 성북구 장위동</td>\n",
       "      <td>아파트</td>\n",
       "      <td>37.619397</td>\n",
       "      <td>127.04663</td>\n",
       "      <td>115.07</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>513</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-10-30</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>서울 성북구</td>\n",
       "      <td>6.699521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       아파트명           동네 건물종류         위도         경도      면적     층      거래년월일  가구수  동수    사용승인년월일       거래가      지역        나이\n",
       "0      0  꿈의숲코오롱하늘채  서울시 성북구 장위동  아파트  37.619397  127.04663  115.07  30.0 2024-04-29  513   5 2017-10-30  100800.0  서울 성북구  6.699521\n",
       "1      1  꿈의숲코오롱하늘채  서울시 성북구 장위동  아파트  37.619397  127.04663  115.07  20.0 2024-04-20  513   5 2017-10-30   98000.0  서울 성북구  6.699521\n",
       "2      2  꿈의숲코오롱하늘채  서울시 성북구 장위동  아파트  37.619397  127.04663  115.07  10.0 2024-02-25  513   5 2017-10-30   95000.0  서울 성북구  6.699521\n",
       "3      3  꿈의숲코오롱하늘채  서울시 성북구 장위동  아파트  37.619397  127.04663  115.07   4.0 2023-07-10  513   5 2017-10-30   90000.0  서울 성북구  6.699521\n",
       "4      4  꿈의숲코오롱하늘채  서울시 성북구 장위동  아파트  37.619397  127.04663  115.07  19.0 2023-01-11  513   5 2017-10-30   80000.0  서울 성북구  6.699521"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>아파트명</th>\n",
       "      <th>동네</th>\n",
       "      <th>건물종류</th>\n",
       "      <th>위도</th>\n",
       "      <th>경도</th>\n",
       "      <th>면적</th>\n",
       "      <th>층</th>\n",
       "      <th>거래년월일</th>\n",
       "      <th>가구수</th>\n",
       "      <th>동수</th>\n",
       "      <th>사용승인년월일</th>\n",
       "      <th>거래가</th>\n",
       "      <th>지역</th>\n",
       "      <th>나이</th>\n",
       "      <th>최단지하철역</th>\n",
       "      <th>역과거리</th>\n",
       "      <th>역사명</th>\n",
       "      <th>근접노선수</th>\n",
       "      <th>역lati</th>\n",
       "      <th>역longi</th>\n",
       "      <th>도보거리</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10115792</th>\n",
       "      <td>10233309</td>\n",
       "      <td>충북혁신도시아모리움내안애</td>\n",
       "      <td>충청북도 진천군 덕산읍</td>\n",
       "      <td>아파트</td>\n",
       "      <td>36.900717</td>\n",
       "      <td>127.534146</td>\n",
       "      <td>111.32</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2023-02-11</td>\n",
       "      <td>842</td>\n",
       "      <td>13</td>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>충북 진천군</td>\n",
       "      <td>6.332649</td>\n",
       "      <td>없음</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>없음</td>\n",
       "      <td>0</td>\n",
       "      <td>51.5074</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10115793</th>\n",
       "      <td>10233310</td>\n",
       "      <td>충북혁신도시아모리움내안애</td>\n",
       "      <td>충청북도 진천군 덕산읍</td>\n",
       "      <td>아파트</td>\n",
       "      <td>36.900717</td>\n",
       "      <td>127.534146</td>\n",
       "      <td>111.32</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2021-09-03</td>\n",
       "      <td>842</td>\n",
       "      <td>13</td>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>충북 진천군</td>\n",
       "      <td>6.332649</td>\n",
       "      <td>없음</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>없음</td>\n",
       "      <td>0</td>\n",
       "      <td>51.5074</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10115794</th>\n",
       "      <td>10233311</td>\n",
       "      <td>충북혁신도시아모리움내안애</td>\n",
       "      <td>충청북도 진천군 덕산읍</td>\n",
       "      <td>아파트</td>\n",
       "      <td>36.900717</td>\n",
       "      <td>127.534146</td>\n",
       "      <td>111.32</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2021-07-21</td>\n",
       "      <td>842</td>\n",
       "      <td>13</td>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>29500.0</td>\n",
       "      <td>충북 진천군</td>\n",
       "      <td>6.332649</td>\n",
       "      <td>없음</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>없음</td>\n",
       "      <td>0</td>\n",
       "      <td>51.5074</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10115795</th>\n",
       "      <td>10233312</td>\n",
       "      <td>도운</td>\n",
       "      <td>경상남도 진주시 하대동</td>\n",
       "      <td>아파트</td>\n",
       "      <td>35.188657</td>\n",
       "      <td>128.128217</td>\n",
       "      <td>60.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>1986-07-14</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>경남 진주시</td>\n",
       "      <td>37.995893</td>\n",
       "      <td>가야대</td>\n",
       "      <td>67635.852051</td>\n",
       "      <td>가야대</td>\n",
       "      <td>1</td>\n",
       "      <td>35.266727</td>\n",
       "      <td>128.86507</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10115796</th>\n",
       "      <td>10233313</td>\n",
       "      <td>도운</td>\n",
       "      <td>경상남도 진주시 하대동</td>\n",
       "      <td>아파트</td>\n",
       "      <td>35.188657</td>\n",
       "      <td>128.128217</td>\n",
       "      <td>60.84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2012-12-18</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>1986-07-14</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>경남 진주시</td>\n",
       "      <td>37.995893</td>\n",
       "      <td>가야대</td>\n",
       "      <td>67635.852051</td>\n",
       "      <td>가야대</td>\n",
       "      <td>1</td>\n",
       "      <td>35.266727</td>\n",
       "      <td>128.86507</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             index           아파트명            동네 건물종류         위도          경도      면적     층      거래년월일  가구수  동수    사용승인년월일      거래가      지역         나이 최단지하철역          역과거리  역사명 근접노선수      역lati     역longi   도보거리\n",
       "10115792  10233309  충북혁신도시아모리움내안애  충청북도 진천군 덕산읍  아파트  36.900717  127.534146  111.32  19.0 2023-02-11  842  13 2018-03-13  35000.0  충북 진천군   6.332649     없음    10000000.0   없음     0    51.5074     0.1278  False\n",
       "10115793  10233310  충북혁신도시아모리움내안애  충청북도 진천군 덕산읍  아파트  36.900717  127.534146  111.32  12.0 2021-09-03  842  13 2018-03-13  45000.0  충북 진천군   6.332649     없음    10000000.0   없음     0    51.5074     0.1278  False\n",
       "10115794  10233311  충북혁신도시아모리움내안애  충청북도 진천군 덕산읍  아파트  36.900717  127.534146  111.32   7.0 2021-07-21  842  13 2018-03-13  29500.0  충북 진천군   6.332649     없음    10000000.0   없음     0    51.5074     0.1278  False\n",
       "10115795  10233312             도운  경상남도 진주시 하대동  아파트  35.188657  128.128217   60.84   1.0 2013-02-15  115   2 1986-07-14   6000.0  경남 진주시  37.995893    가야대  67635.852051  가야대     1  35.266727  128.86507  False\n",
       "10115796  10233313             도운  경상남도 진주시 하대동  아파트  35.188657  128.128217   60.84   1.0 2012-12-18  115   2 1986-07-14   6000.0  경남 진주시  37.995893    가야대  67635.852051  가야대     1  35.266727  128.86507  False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()\n",
    "df_final[df_final['역과거리'] > 10000].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop(columns=['역사명'])\n",
    "df_final.to_csv(\"전국_도시철도역사정보_좌표포함_지하철거리계산.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "from qrytool import load_data_into_dataframe, insert_dataframe_into_table\n",
    "from geopy.distance import geodesic\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import os\n",
    "import ray\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# if not df_final :\n",
    "df_final = pd.read_csv(\"전국_도시철도역사정보_좌표포함_지하철거리계산.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['거래년월일'] = pd.to_datetime(df_final['거래년월일'])\n",
    "df_final['사용승인년월일'] = pd.to_datetime(df_final['사용승인년월일'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction from '거래일' if necessary\n",
    "df_final['거래연'] = df_final['거래년월일'].dt.year\n",
    "df_final['거래월'] = df_final['거래년월일'].dt.month\n",
    "df_final['거래일'] = df_final['거래년월일'].dt.day\n",
    "\n",
    "df_final['사용승인연'] = df_final['사용승인년월일'].dt.year\n",
    "df_final['사용승인월'] = df_final['사용승인년월일'].dt.month\n",
    "df_final['사용승인일'] = df_final['사용승인년월일'].dt.day\n",
    "# Select features and target\n",
    "features = ['아파트명', '동네', '건물종류', '위도', '경도', '층', '거래연', '거래월', '거래일', '사용승인연', '사용승인월', '사용승인일', '가구수', '동수', '나이', '역과거리', '근접노선수', '역lati', '역longi', '도보거리']\n",
    "\n",
    "X = df_final[features]\n",
    "y = df_final['거래가']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10115797, 20)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import DMatrix, train\n",
    "from xgboost.callback import TrainingCallback\n",
    "import wandb\n",
    "import joblib\n",
    "\n",
    "# Close any previous W&B runs\n",
    "wandb.finish()\n",
    "\n",
    "# Initialize W&B\n",
    "wandb.init(project=\"xgboost-best-mon\", name=\"xgboost-best\")\n",
    "\n",
    "# Ensure the target variable does not contain NaN, infinity, or values too large\n",
    "y = y.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Drop corresponding rows in X where y is NaN\n",
    "valid_indices = y.dropna().index\n",
    "X = X.loc[valid_indices]\n",
    "y = y.loc[valid_indices]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ColumnTransformer for preprocessing\n",
    "numeric_features = ['위도', '경도', '층', '거래연', '거래월', '거래일', '사용승인연', '사용승인월', '사용승인일',\n",
    "                    '가구수', '동수', '나이', '역과거리', '근접노선수', '역lati', '역longi']\n",
    "categorical_features = ['아파트명', '동네', '건물종류', '도보거리']\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Preprocess the training and test data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "joblib.dump(preprocessor, 'feature_preprocessor.pkl')\n",
    "\n",
    "# Convert to DMatrix\n",
    "dtrain = DMatrix(X_train_transformed, label=y_train)\n",
    "dtest = DMatrix(X_test_transformed, label=y_test)\n",
    "\n",
    "# Set up the parameters for training with the best hyperparameters\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'tree_method': 'hist',\n",
    "    'colsample_bytree': 0.7,\n",
    "    'learning_rate': 0.2,\n",
    "    'max_depth': 10,\n",
    "    'alpha': 100,\n",
    "    'device': 'cuda'\n",
    "}\n",
    "\n",
    "\n",
    "# Custom callback for logging metrics to W&B\n",
    "class WandbCallback(TrainingCallback):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def after_iteration(self, model, epoch, evals_log):\n",
    "        for eval_set in evals_log:\n",
    "            for metric in evals_log[eval_set]:\n",
    "                value = evals_log[eval_set][metric][-1]\n",
    "                wandb.log({f\"{eval_set}_{metric}\": value, \"epoch\": self.epoch})\n",
    "        self.epoch += 1\n",
    "        return False  # Return False to continue training\n",
    "\n",
    "\n",
    "# Train the model and log metrics with a custom callback\n",
    "num_boost_round = 300\n",
    "evals = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "bst = train(params, dtrain, num_boost_round, evals=evals,\n",
    "            early_stopping_rounds=10, verbose_eval=False,\n",
    "            callbacks=[WandbCallback()])\n",
    "\n",
    "# Make predictions using predict with the DMatrix format for GPU\n",
    "predictions = bst.predict(dtest)\n",
    "\n",
    "# Calculate Mean Absolute Error as an example metric\n",
    "mae = np.mean(np.abs(predictions - y_test))\n",
    "print(\"Mean Absolute Error: \", mae)\n",
    "\n",
    "# Log the final MAE and save the model to W&B\n",
    "wandb.log({\"Mean Absolute Error\": mae})\n",
    "bst.save_model(\"xgboost_model.json\")\n",
    "wandb.save(\"xgboost_model.json\")\n",
    "\n",
    "# Extract feature importance\n",
    "feature_importance = bst.get_score(importance_type='weight')\n",
    "print(\"Feature importance from model:\")\n",
    "print(feature_importance)\n",
    "# Get the feature names from the model\n",
    "# model_feature_names = bst.feature_names\n",
    "# print(\"Model feature names:\")\n",
    "# print(model_feature_names)\n",
    "# if model_feature_names is not None:\n",
    "#     feature_importance = {model_feature_names[int(k[1:])]: v for k, v in feature_importance.items()}\n",
    "\n",
    "\n",
    "# Get the feature names\n",
    "encoder = preprocessor.named_transformers_['cat']\n",
    "categorical_feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "feature_names = np.concatenate([numeric_features, categorical_feature_names])\n",
    "print(\"feature_names\", feature_names)\n",
    "# Create a dictionary to map model feature names to preprocessor feature names\n",
    "feature_name_mapping = {f'f{i}': feature_names[i] for i in range(len(feature_names))}\n",
    "print(\"Feature name mapping:\")\n",
    "print(feature_name_mapping)\n",
    "\n",
    "# Map the feature importance to the preprocessor feature names\n",
    "mapped_feature_importance = {feature_name_mapping.get(f, f): imp for f, imp in feature_importance.items()}\n",
    "print(\"Mapped feature importance:\")\n",
    "print(mapped_feature_importance)\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': list(mapped_feature_importance.keys()),\n",
    "    'importance': list(mapped_feature_importance.values())\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "# Debug print\n",
    "print(\"Feature importance data frame:\")\n",
    "print(importance_df)\n",
    "\n",
    "# Aggregate importance at the field level\n",
    "field_importance = {}\n",
    "for feature, importance in zip(importance_df['feature'], importance_df['importance']):\n",
    "    field = feature.split('_')[0] if '_' in feature else feature\n",
    "    if field in field_importance:\n",
    "        field_importance[field] += importance\n",
    "    else:\n",
    "        field_importance[field] = importance\n",
    "\n",
    "\n",
    "# Create a DataFrame for field-level importance\n",
    "field_importance_df = pd.DataFrame({\n",
    "    'field': field_importance.keys(),\n",
    "    'importance': field_importance.values()\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Debug print\n",
    "print(\"Field importance data frame:\")\n",
    "print(field_importance_df)\n",
    "\n",
    "# Log field-level importance to W&B as a table\n",
    "field_importance_table = wandb.Table(dataframe=field_importance_df)\n",
    "wandb.log({\"Field Importance Table\": field_importance_table})\n",
    "\n",
    "# Create a field-level importance bar chart\n",
    "wandb.log({\n",
    "    \"Field Importance Chart\": wandb.plot.bar(\n",
    "        field_importance_table,\n",
    "        \"field\",\n",
    "        \"importance\",\n",
    "        title=\"Field-Level Feature Importance\"\n",
    "    )\n",
    "})\n",
    "\n",
    "# Close the current W&B run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost가 GPU와 동작하는 지 점검\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Check if GPU is available and XGBoost is compiled with GPU support\n",
    "\n",
    "\n",
    "def check_xgboost_gpu():\n",
    "    params = {'tree_method': 'hist', 'device': 'cuda:0'}\n",
    "    dmatrix = xgb.DMatrix(data=[[1, 2], [3, 4]], label=[1, 2])\n",
    "    try:\n",
    "        # Perform a simple training to check for GPU availability\n",
    "        xgb.train(params, dmatrix, num_boost_round=1)\n",
    "        print(\"XGBoost GPU is available and the model is compiled with GPU support.\")\n",
    "    except xgb.core.XGBoostError as e:\n",
    "        print(\"XGBoost GPU is not available or not compiled with GPU support.\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "check_xgboost_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor, DMatrix, train\n",
    "from xgboost.callback import TrainingCallback\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "# Close any previous W&B runs\n",
    "wandb.finish()\n",
    "\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"train_complex_data.ipynb\"\n",
    "# Initialize W&B\n",
    "wandb.init(project=\"xgboost-opt-mon\", name=\"xgboost-opt\")\n",
    "\n",
    "# Ensure the target variable does not contain NaN, infinity, or values too large\n",
    "y = y.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Drop corresponding rows in X where y is NaN\n",
    "valid_indices = y.dropna().index\n",
    "X = X.loc[valid_indices]\n",
    "y = y.loc[valid_indices]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ColumnTransformer for preprocessing\n",
    "numeric_features = ['위도', '경도', '층', '거래연', '거래월', '거래일', '사용승인연', '사용승인월', '사용승인일',\n",
    "                    '가구수', '동수', '나이', '역과거리', '근접노선수', '역lati', '역longi']\n",
    "categorical_features = ['아파트명', '동네', '건물종류', '도보거리']\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Custom callback for logging metrics to W&B\n",
    "\n",
    "\n",
    "class WandbCallback(TrainingCallback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.epoch = 0\n",
    "\n",
    "    def after_iteration(self, model, epoch, evals_log):\n",
    "        for eval_set in evals_log:\n",
    "            for metric in evals_log[eval_set]:\n",
    "                value = evals_log[eval_set][metric][-1]\n",
    "                wandb.log({f\"{eval_set}_{metric}\": value, \"epoch\": self.epoch})\n",
    "        self.epoch += 1\n",
    "        return False  # Return False to continue training\n",
    "\n",
    "    def before_training(self, model):\n",
    "        self.epoch = 0  # Reset epoch counter for each new training session\n",
    "        return model\n",
    "\n",
    "\n",
    "# Create the pipeline with XGBRegressor\n",
    "xgb_model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    tree_method='hist',\n",
    "    device='cuda',\n",
    "    eval_metric='rmse',  # Log RMSE by default\n",
    "    callbacks=[WandbCallback()],\n",
    "    use_label_encoder=False,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb_model)\n",
    "])\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'model__colsample_bytree': [0.3, 0.5, 0.7],\n",
    "    'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'model__max_depth': [5, 7, 10],\n",
    "    'model__alpha': [1, 10, 100],\n",
    "    'model__n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    n_jobs=2,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the model with GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Transform the test data using the preprocessor\n",
    "X_test_transformed = best_model.named_steps['preprocessor'].transform(X_test)\n",
    "\n",
    "# Convert transformed data to DMatrix and ensure it's on the correct device\n",
    "dtest = DMatrix(X_test_transformed, label=y_test)\n",
    "\n",
    "# Make predictions using predict with the DMatrix format for GPU\n",
    "predictions = best_model.named_steps['model'].predict(X_test_transformed)\n",
    "\n",
    "# Calculate Mean Absolute Error as an example metric\n",
    "mae = np.mean(np.abs(predictions - y_test))\n",
    "print(\"Mean Absolute Error: \", mae)\n",
    "\n",
    "# Log the final MAE and save the model to W&B\n",
    "wandb.log({\"Mean Absolute Error\": mae, \"Best Params\": best_params})\n",
    "best_model.named_steps['model'].save_model(\"xgboost_model.json\")\n",
    "wandb.save(\"xgboost_model.json\")\n",
    "\n",
    "# Close the current W&B run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 준비\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/max/miniconda3/lib/python3.10/site-packages/ray/thirdparty_files', '/home/max/cleanbeding/naver-realestate/TIPS', '/home/max/miniconda3/lib/python310.zip', '/home/max/miniconda3/lib/python3.10', '/home/max/miniconda3/lib/python3.10/lib-dynload', '', '/home/max/miniconda3/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import ray\n",
    "import os\n",
    "import concurrent.futures\n",
    "from geopy.distance import geodesic\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from qrytool import load_data_into_dataframe, insert_dataframe_into_table\n",
    "import warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "print(sys.path)\n",
    "\n",
    "\n",
    "def split_address(address):\n",
    "    match = None\n",
    "    group2 = None\n",
    "    group3 = None\n",
    "    group4 = None\n",
    "    group5 = None\n",
    "    group6 = None\n",
    "    addr1 = None\n",
    "    addr2 = None\n",
    "    if pd.notnull(address):\n",
    "        pattern = re.compile(\n",
    "            r\"\\s[\\-0-9]+\\s(\\([가-힣a-zA-Z0-9,\\s]+\\)\\s)?(.*)|.*구.*동\\s(.*\\s아파트)(.*)|[\\s로길동]+[\\-0-9번지]+(\\([가-힣a-zA-Z0-9,\\s]+\\))?([,\\s].*)\"\n",
    "        )\n",
    "        match = pattern.search(address)  # search를 사용하여 전체 문자열에서 패턴 매치\n",
    "\n",
    "        if match:\n",
    "            group2 = match.group(2)\n",
    "            group3 = match.group(3)\n",
    "            group4 = match.group(4)\n",
    "            group5 = match.group(5)\n",
    "            group6 = match.group(6)\n",
    "            # print(\n",
    "            #     f\"{ match.group(1)} | {group2}|{group3}|{group4}|{group5}|{group6}|\"\n",
    "            # )\n",
    "            if group2:\n",
    "                addr1 = address.replace(group2, \"\")\n",
    "                addr2 = group2\n",
    "            elif group3:\n",
    "                if \"아파트\" in group3:\n",
    "                    addr1 = address.replace(group4, \"\")\n",
    "                    addr2 = group4\n",
    "                else:\n",
    "                    addr1 = address.replace(group3, \"\")\n",
    "                    addr2 = group3\n",
    "            elif group6.strip():\n",
    "                addr1 = address.replace(group6, \"\")\n",
    "                addr2 = group6.replace(\",\", \"\").strip()\n",
    "            else:\n",
    "                addr1 = address\n",
    "                addr2 = None\n",
    "            ret1 = addr1\n",
    "            ret2 = addr2\n",
    "        else:\n",
    "            print(\"No match :\" + address)\n",
    "            ret1 = address\n",
    "            ret2 = None\n",
    "    return ret1, ret2\n",
    "\n",
    "\n",
    "def get_floor(room_number):\n",
    "    if not room_number:\n",
    "        return \"\"\n",
    "    # Check if the room number is a string\n",
    "    if isinstance(room_number, str):\n",
    "        # Check if the string starts with \"비\"\n",
    "        if room_number.startswith(\"B\") or room_number.startswith(\"b\"):\n",
    "            # Remove \"비\" from the start of the string\n",
    "            room_number = room_number[1:]\n",
    "            # Indicate that this is a basement floor\n",
    "            floor_indicator = '지하'\n",
    "        else:\n",
    "            floor_indicator = ''\n",
    "        # Remove the string \"호\" from the room number\n",
    "        room_number = room_number.replace(\"호\", \"\")\n",
    "\n",
    "        # Check if the room number is a digit\n",
    "        if room_number.isdigit():\n",
    "            # Take all but the last two digits to get the floor number\n",
    "            floor_number = room_number[:-2]\n",
    "            return floor_indicator + str(floor_number) + '층'\n",
    "        else:\n",
    "            return \"Invalid room number\"\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def is_same_str_by_rem_space(a, b):\n",
    "    a = a.strip()\n",
    "    b = b.replace(' ', '').strip()\n",
    "    if len(a) == len(b) and a == b:\n",
    "        return a\n",
    "\n",
    "\n",
    "def has_end_only_braket_string(s):\n",
    "    # \"(\"가 없고, \")\"가 하나만 있으며, \")\"로 끝나는지 확인\n",
    "    return s.count('(') == 0 and s.count(')') == 1 and s.endswith(')')\n",
    "\n",
    "\n",
    "def has_only_one_set_braket_string(s):\n",
    "    return s.count('(') == 1 and s.count(')') == 1 and s.startswith('(') and s.endswith(')')\n",
    "\n",
    "\n",
    "def has_middle_bracket(s):\n",
    "    return \")\" in s and not s.endswith(\")\") and not s.startswith(\")\")\n",
    "\n",
    "\n",
    "def is_single_word(s):\n",
    "    # 남은 문자열 내에 XXX도 또는 XXX호가 보이지 않는 영문,숫자,한글이 조합된 문자열이라면 True\n",
    "    s = s.replace(' ', '')\n",
    "    pattern = r'([\\dA-Za-z가나다라마바]+동)*\\s*(\\d+[호])*'\n",
    "    match = re.search(pattern, s)\n",
    "    # match가 None이면 정규식과 일치하는 부분이 없는 것이므로 False 반환\n",
    "    if match and match.group():\n",
    "        return False\n",
    "    else:\n",
    "        return bool(re.match(r'^[가-힣A-Za-z0-9]+$', s))\n",
    "    # return bool(re.match(r'^[가-힣A-Za-z]+$', s))\n",
    "\n",
    "\n",
    "def has_not_relevant_pattern(s):\n",
    "    pattern = r\"^[\\s\\d\\-]+$|^[\\s\\d]+층\\s*$\"\n",
    "    match = re.search(pattern, s)\n",
    "    if match:\n",
    "        return True\n",
    "\n",
    "\n",
    "def get_complex_name(remained_str):\n",
    "    remained_str = remained_str.strip()\n",
    "    if remained_str == \"\":\n",
    "        return \"\", \"\"\n",
    "    if remained_str[0] == \"(\":\n",
    "        remained_str = remained_str[1:].strip()\n",
    "\n",
    "    if has_only_one_set_braket_string(remained_str):\n",
    "        return remained_str.replace(\"(\", \"\").replace(\")\", \"\").strip(), \"\"\n",
    "    elif has_end_only_braket_string(remained_str):\n",
    "        return remained_str.replace(\")\", \"\").strip(), \"\"\n",
    "    elif has_not_relevant_pattern(remained_str):\n",
    "        print(\"예외문자열:\" + remained_str)\n",
    "        return \"\", remained_str\n",
    "    elif has_middle_bracket(remained_str):\n",
    "        # print(\"괄호포함문자열:\" + remained_str)\n",
    "        names = remained_str.split(sep=\")\")\n",
    "        if len(names) > 2:\n",
    "            print(\"이상한문자열:\" + remained_str)\n",
    "        remained_str = \"\" if is_same_str_by_rem_space(names[0], names[1]) else names[1].strip()\n",
    "        return names[0].strip(), remained_str\n",
    "        # return get_super_str(names[0].strip(), names[1].strip())\n",
    "    elif is_single_word(remained_str):\n",
    "        # print(\"문자열만 남은 경우:\", remained_str)\n",
    "        return remained_str, \"\"\n",
    "\n",
    "    else:\n",
    "        print(\"추가고려 필요 ==> \" + remained_str)\n",
    "        return \"\", remained_str\n",
    "\n",
    "\n",
    "def get_dong_complex_name(remained_str):\n",
    "    dong_name = ''\n",
    "    complex_name = ''\n",
    "    sep = ''\n",
    "    pattern = r'\\(([가-힣\\d]+[동가리]{1})([\\s,)]){1}'\n",
    "    if not remained_str or remained_str.strip() == \"\":\n",
    "        return \"\", \"\", \"\"\n",
    "    match = re.search(pattern, remained_str)\n",
    "    if match:\n",
    "        dong_name = match.group(1)  # 동명 추출\n",
    "        sep = match.group(2)  # 동명 추출\n",
    "        remained_str = remained_str.replace('(' + dong_name + sep, '').strip()\n",
    "        complex_name, remained_str = get_complex_name(remained_str)\n",
    "    else:\n",
    "        complex_name, remained_str = get_complex_name(remained_str)\n",
    "    return dong_name, complex_name, remained_str\n",
    "\n",
    "\n",
    "def get_complex_dong_ho_floor(address, lat, lon):\n",
    "    addr1, addr2 = split_address(address)\n",
    "\n",
    "    # print(addresses_df.head())\n",
    "    patterns = [\n",
    "        r'([\\dA-Za-z가나다라마바]+동)\\s*(\\w+[호]{0,1})\\s*$',\n",
    "        r'\\)\\s*(\\w+)\\s*[-ㅡ]\\s*([\\dA-Za-z]+호*)\\s*$',\n",
    "        r'\\)\\s*[가-힣A-Za-z\\.\\,]+\\s*([\\dABCDEabcde]*)\\s*[-ㅡ\\s]{1}\\s*([\\dA-Za-z]+호*)\\s*$',\n",
    "        r'\\s*(\\w+)\\s*[-ㅡ]\\s*([\\dA-Za-z]+호*)\\s*$',\n",
    "        r'(아파트동)\\s*(\\w+[호]{0,1})\\s*$',\n",
    "        r'(오피스텔동)\\s*(\\w+[호]{0,1})\\s*$',\n",
    "        r'\\)\\s*([\\dA-Za-z]+호)\\s*$',\n",
    "        r'\\)\\s*[가-힣A-Za-z\\.\\,]+([\\dA-Za-z]+호)\\s*$',\n",
    "        r'\\s*([\\dA-Za-z]+호)\\s*$',\n",
    "    ]\n",
    "    dong = \"\"\n",
    "    ho = \"\"\n",
    "    temp_addr2 = \"\"\n",
    "    dong_name = \"\"\n",
    "    complex_name = \"\"\n",
    "    for idx, pattern in enumerate(patterns):\n",
    "        if not addr2 or addr2.strip() == \"\":\n",
    "            continue\n",
    "        # print(row['회원주소2'])\n",
    "        match = re.search(pattern, addr2)\n",
    "        if match:\n",
    "            if len(match.groups()) == 1:\n",
    "                ho = match.group(1)  # 호만 추출될 경우\n",
    "                temp_addr2 = addr2.replace(ho, '')\n",
    "                if '호' not in ho:\n",
    "                    ho = ho + '호'\n",
    "            elif len(match.groups()) >= 2:\n",
    "                dong = match.group(1)  # 동 추출\n",
    "                ho = match.group(2)  # 호 추출\n",
    "                addr2 = addr2.replace(ho, '')\n",
    "                temp_addr2 = addr2.replace(dong, '')\n",
    "                if '호' not in ho:\n",
    "                    ho = ho + '호'\n",
    "                if len(dong) >= 1 and '동' not in dong:\n",
    "                    dong = dong + '동'\n",
    "                if idx in [1, 2, 3]:\n",
    "                    temp_addr2 = temp_addr2.replace('-', '')\n",
    "            break\n",
    "    temp_addr2 = temp_addr2.strip()\n",
    "    dong_name, complex_name, remained_str = get_dong_complex_name(temp_addr2)\n",
    "\n",
    "    return complex_name, dong, ho, get_floor(ho)\n",
    "\n",
    "\n",
    "def calculate_min_distance(row, df_subway):\n",
    "    lat1, lon1 = row['위도'], row['경도']\n",
    "    min_distance = float('inf')\n",
    "    nearest_station = None\n",
    "\n",
    "    for _, subway_row in df_subway.iterrows():\n",
    "        lat2, lon2 = subway_row['lati'], subway_row['longi']\n",
    "        distance = geodesic((lat1, lon1), (lat2, lon2)).meters\n",
    "\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            nearest_station = subway_row\n",
    "\n",
    "    return {\n",
    "        'index': row['index'],\n",
    "        '최단지하철역': nearest_station['역사명'],\n",
    "        '역과거리': min_distance,\n",
    "        '역사명': nearest_station['역사명'],\n",
    "        '근접노선수': nearest_station['근접노선수'],\n",
    "        '역lati': nearest_station['lati'],\n",
    "        '역longi': nearest_station['longi'],\n",
    "        '도보거리': min_distance <= 500\n",
    "    }\n",
    "\n",
    "\n",
    "def get_address_by_name_mdn(name, mdn):\n",
    "    qry_name_mdn = f\"SELECT all_id,이름,결제전화,회원주소,회원주소1,회원lati,회원longi,가입일시 FROM customatrix WHERE 이름='{name}' and 결제전화 like '%{mdn}'\"\n",
    "    df = load_data_into_dataframe(qry_name_mdn)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_address_by_cid(cid):\n",
    "    qry_cid = f\"SELECT all_id,이름,결제전화,회원주소,회원주소1,회원lati,회원longi,가입일시 FROM customatrix WHERE all_id={cid}\"\n",
    "    df = load_data_into_dataframe(qry_cid)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_address_by_addr(addr):\n",
    "    qry_cid = f\"SELECT all_id,이름,결제전화,회원주소,회원주소1,회원lati,회원longi,가입일시 FROM customatrix WHERE 회원주소={addr}\"\n",
    "    df = load_data_into_dataframe(qry_cid)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예외문자열:13층\n",
      "추가고려 필요 ==> 리젠빌(3차))\n",
      "추가고려 필요 ==> 절영아파트(3차))\n",
      "추가고려 필요 ==> 힐스테이트 미사역 그랑파사쥬(11-1BL))\n",
      "추가고려 필요 ==> 106동\n",
      "추가고려 필요 ==> 힐스테이트 미사역 그랑파사쥬(11-1BL))\n",
      "추가고려 필요 ==> 하남미사 롯데캐슬 헤븐시티 Ⅰ\n",
      "추가고려 필요 ==> 원효루미니아파트 101동(B동)\n",
      "예외문자열:4층\n",
      "추가고려 필요 ==> 건설기술인회관(별관))\n",
      "추가고려 필요 ==> 건설기술인회관(별관))\n",
      "추가고려 필요 ==> 102동 오피스텔\n",
      "추가고려 필요 ==> 강변그대家(가) River View(리버 뷰))\n",
      "추가고려 필요 ==> 잠실 벨솔레 오피스텔 (방이2동 주민센터))\n",
      "추가고려 필요 ==> 부개주공아파트(6단지))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2210, 26)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qry = \"\"\"\n",
    "SELECT DISTINCT ON (cm.이름, cm.결제전화)\n",
    "    nc.complex_no,\n",
    "    nc.complex_name 아파트명,\n",
    "    nc.cortar_address 동네,\n",
    "    nc.real_estate_type_name 건물종류,\n",
    "    nc.latitude 위도,\n",
    "    nc.longitude 경도,\n",
    "    0 층,\n",
    "    nc.use_approve_ymd 사용승인년월일,\n",
    "    nc.total_household_count 가구수,\n",
    "    nc.total_building_count 동수,\n",
    "    nc.cortar_address naver주소,\n",
    "    CURRENT_DATE 거래년월일,\n",
    "    cm.all_id,cm.이름,cm.결제전화,cm.회원주소,cm.회원주소1,cm.회원lati,cm.회원longi,cm.가입일시 FROM customatrix cm\n",
    "LEFT JOIN alladdr_naver_joins nc ON  cm.회원lati=nc.lati AND cm.회원longi=nc.longi\n",
    "WHERE complex_no IS NOT NULL ORDER BY cm.이름, cm.결제전화;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df = load_data_into_dataframe(qry)\n",
    "\n",
    "df['거래년월일'] = pd.to_datetime(df['거래년월일'], errors='coerce')\n",
    "df['사용승인년월일'] = pd.to_datetime(df['사용승인년월일'], errors='coerce')\n",
    "# df['층'] = df['건물호'].apply(get_floor), df['건물층'])\n",
    "\n",
    "\n",
    "# Process '동네' column\n",
    "df['지역'] = df['동네'].apply(process_region_naver_cortar_addr)\n",
    "\n",
    "# Apply the function to each row in the dataframe\n",
    "results = df.apply(lambda row: get_complex_dong_ho_floor(row['회원주소'], row['회원lati'], row['회원longi']), axis=1)\n",
    "\n",
    "# Split the results into separate columns and add them to the dataframe\n",
    "df[['complex_name', '동호', '호', '층']] = pd.DataFrame(results.tolist(), index=df.index)\n",
    "\n",
    "\n",
    "# 오늘 날짜를 기준으로 건물의 나이 계산\n",
    "today = datetime.now()\n",
    "df['나이'] = (today - df['사용승인년월일']).dt.days / 365.25  # 일수를 년도로 변환\n",
    "df.reset_index(inplace=True)\n",
    "df = df[~df['지역'].str.contains('제주')]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지하철 좌표정보와 해당 주소지의 거리를 계산하여 다음의 피처들을 계산해내고 이를 csv 파일에 저장해두는 로직\n",
    "\n",
    "'최단지하철역', '역과거리', '역사명', '근접노선수', '역lati', '역longi', '도보거리'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-12 22:21:27,822\tINFO worker.py:1771 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e170830f2da844d88ce03ff712a3497e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows: |          | 0/0 [00:00<?, ?it/s]   0%"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 순차적으로 처리 실행\n",
    "batch_size = 10\n",
    "num_cores = 23\n",
    "# 결과 저장할 CSV 파일 초기화\n",
    "output_file = 'output_inference.csv'\n",
    "\n",
    "\n",
    "if not ray.is_initialized():\n",
    "    ray.init(num_cpus=23)\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def process_batch(batch, df_subway):\n",
    "    results = []\n",
    "    for _, row in batch.iterrows():\n",
    "        result = calculate_min_distance(row, df_subway)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "# 데이터 로드\n",
    "file_path = \"./전국_도시철도역사정보_좌표포함.xlsx\"\n",
    "df_subway = pd.read_excel(file_path)\n",
    "df_subway = prepare_subway_data(df_subway)\n",
    "\n",
    "# 처리된 인덱스 추적\n",
    "completed_indices = set()\n",
    "if os.path.exists(output_file):\n",
    "    processed_results = pd.read_csv(output_file)\n",
    "    completed_indices = set(processed_results['index'])\n",
    "else:\n",
    "    # 결과 파일에 헤더 작성\n",
    "    pd.DataFrame(columns=['index', '최단지하철역', '역과거리', '역사명', '근접노선수', '역lati', '역longi', '도보거리']).to_csv(output_file, index=False)\n",
    "\n",
    "# 처리되지 않은 행들만 선택\n",
    "remaining_rows = df[~df['index'].isin(completed_indices)]\n",
    "total_rows = len(remaining_rows)\n",
    "\n",
    "# Custom bar format for tqdm\n",
    "bar_format = '{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}] {percentage:3.0f}%'\n",
    "\n",
    "# Process the data in batches\n",
    "with tqdm(total=total_rows, desc=\"Processing rows\", bar_format=bar_format) as pbar:\n",
    "    futures = []\n",
    "    start_index = 0\n",
    "\n",
    "    while start_index < total_rows or futures:\n",
    "        # Submit tasks until the core limit is reached\n",
    "        while len(futures) < num_cores and start_index < total_rows:\n",
    "            batch = remaining_rows.iloc[start_index:start_index + batch_size]\n",
    "            future = process_batch.remote(batch, df_subway)\n",
    "            futures.append(future)\n",
    "            start_index += batch_size\n",
    "\n",
    "        # Wait for the first available future to complete\n",
    "        if futures:\n",
    "            ready_futures, remaining_futures = ray.wait(futures, num_returns=1)\n",
    "            futures = remaining_futures\n",
    "\n",
    "            for ready_future in ready_futures:\n",
    "                result = ray.get(ready_future)\n",
    "                result_df = pd.DataFrame(result)\n",
    "                result_df.to_csv(output_file, mode='a', header=False, index=False)\n",
    "                pbar.update(batch_size)\n",
    "\n",
    "# Shut down Ray\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저장된 지하쳘역 관련 피처들을 기본 학습데이터와 조인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2210, 8), (2210, 33))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# processed_results = pd.read_csv(output_file, header=None, names=['index', '최단지하철역', '역과거리', '역사명', '근접노선수', '역lati', '역longi', '도보거리'])\n",
    "processed_results = pd.read_csv(output_file)\n",
    "\n",
    "# Ensure 'index' is the correct data type\n",
    "# df.reset_index(inplace=True)\n",
    "df_merged = df.merge(processed_results, on='index')\n",
    "df_merged.drop(columns=['역사명'])\n",
    "df_merged.to_csv(\"고객주소지기준_학습데이터에_지하철거리계산데이터포함.csv\", index=False)\n",
    "processed_results.shape, df_merged.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 저장된 에측 대상 데이터 로드후 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv(\"고객주소지기준_학습데이터에_지하철거리계산데이터포함.csv\")\n",
    "\n",
    "# Feature extraction from '거래일' if necessary\n",
    "df_final = df_merged.copy()\n",
    "\n",
    "df_final['거래년월일'] = pd.to_datetime(df_final['거래년월일'])\n",
    "df_final['사용승인년월일'] = pd.to_datetime(df_final['사용승인년월일'])\n",
    "\n",
    "df_final['거래연'] = df_final['거래년월일'].dt.year\n",
    "df_final['거래월'] = df_final['거래년월일'].dt.month\n",
    "df_final['거래일'] = df_final['거래년월일'].dt.day\n",
    "\n",
    "df_final['사용승인연'] = df_final['사용승인년월일'].dt.year\n",
    "df_final['사용승인월'] = df_final['사용승인년월일'].dt.month\n",
    "df_final['사용승인일'] = df_final['사용승인년월일'].dt.day\n",
    "# '층' 문자를 제거하고 숫자형으로 변환하는 함수 정의\n",
    "\n",
    "\n",
    "def clean_floor_value(floor):\n",
    "    if isinstance(floor, str):\n",
    "        floor = floor.replace('층', '')\n",
    "        # floor = floor.replace('지하', '-')\n",
    "        if floor == '' or floor == 'Invalid room number':\n",
    "            floor = '1'  # 빈 값 또는 'Invalid room number'을 1로 대체\n",
    "        return int(floor)\n",
    "    return floor\n",
    "\n",
    "\n",
    "df_final = df_final[~df_final['층'].str.contains('지하')]\n",
    "# df_final의 '층' 열에 함수 적용\n",
    "df_final['층'] = df_final['층'].apply(clean_floor_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['층'].unique()\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델로드후 준비된 데이터로 인퍼런스\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>위도</th>\n",
       "      <th>경도</th>\n",
       "      <th>층</th>\n",
       "      <th>거래연</th>\n",
       "      <th>거래월</th>\n",
       "      <th>거래일</th>\n",
       "      <th>사용승인연</th>\n",
       "      <th>사용승인월</th>\n",
       "      <th>사용승인일</th>\n",
       "      <th>가구수</th>\n",
       "      <th>동수</th>\n",
       "      <th>나이</th>\n",
       "      <th>역과거리</th>\n",
       "      <th>근접노선수</th>\n",
       "      <th>역lati</th>\n",
       "      <th>역longi</th>\n",
       "      <th>아파트명</th>\n",
       "      <th>동네</th>\n",
       "      <th>건물종류</th>\n",
       "      <th>도보거리</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36.476078</td>\n",
       "      <td>127.146003</td>\n",
       "      <td>14</td>\n",
       "      <td>2024</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>312</td>\n",
       "      <td>6</td>\n",
       "      <td>29.724846</td>\n",
       "      <td>34477.676883</td>\n",
       "      <td>1</td>\n",
       "      <td>36.777541</td>\n",
       "      <td>127.052751</td>\n",
       "      <td>한빛</td>\n",
       "      <td>충청남도 공주시 신관동</td>\n",
       "      <td>아파트</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.268165</td>\n",
       "      <td>127.000106</td>\n",
       "      <td>10</td>\n",
       "      <td>2024</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>18.324435</td>\n",
       "      <td>223.730997</td>\n",
       "      <td>2</td>\n",
       "      <td>37.266162</td>\n",
       "      <td>126.999821</td>\n",
       "      <td>세진브론즈빌</td>\n",
       "      <td>경기도 수원시 팔달구 매산로1가</td>\n",
       "      <td>오피스텔</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.456136</td>\n",
       "      <td>126.653394</td>\n",
       "      <td>26</td>\n",
       "      <td>2024</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>936.417680</td>\n",
       "      <td>1</td>\n",
       "      <td>37.448191</td>\n",
       "      <td>126.649832</td>\n",
       "      <td>인천효성해링턴타워인하</td>\n",
       "      <td>인천시 미추홀구 용현동</td>\n",
       "      <td>오피스텔</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.532110</td>\n",
       "      <td>127.069120</td>\n",
       "      <td>5</td>\n",
       "      <td>2024</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>279</td>\n",
       "      <td>4</td>\n",
       "      <td>14.825462</td>\n",
       "      <td>219.841698</td>\n",
       "      <td>1</td>\n",
       "      <td>37.531590</td>\n",
       "      <td>127.066720</td>\n",
       "      <td>이튼타워리버5차</td>\n",
       "      <td>서울시 광진구 자양동</td>\n",
       "      <td>아파트</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37.502964</td>\n",
       "      <td>126.856017</td>\n",
       "      <td>16</td>\n",
       "      <td>2024</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>987</td>\n",
       "      <td>13</td>\n",
       "      <td>25.382615</td>\n",
       "      <td>943.409092</td>\n",
       "      <td>1</td>\n",
       "      <td>37.494698</td>\n",
       "      <td>126.858504</td>\n",
       "      <td>고척대우</td>\n",
       "      <td>서울시 구로구 고척동</td>\n",
       "      <td>아파트</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          위도          경도   층   거래연  거래월  거래일   사용승인연  사용승인월  사용승인일  가구수  동수         나이          역과거리  근접노선수      역lati      역longi         아파트명                 동네  건물종류   도보거리\n",
       "0  36.476078  127.146003  14  2024    7   12  1994.0   10.0   22.0  312   6  29.724846  34477.676883      1  36.777541  127.052751           한빛       충청남도 공주시 신관동   아파트  False\n",
       "1  37.268165  127.000106  10  2024    7   12  2006.0    3.0   17.0  260   1  18.324435    223.730997      2  37.266162  126.999821       세진브론즈빌  경기도 수원시 팔달구 매산로1가  오피스텔   True\n",
       "2  37.456136  126.653394  26  2024    7   12     NaN    NaN    NaN  628   1        NaN    936.417680      1  37.448191  126.649832  인천효성해링턴타워인하       인천시 미추홀구 용현동  오피스텔  False\n",
       "3  37.532110  127.069120   5  2024    7   12  2009.0    9.0   15.0  279   4  14.825462    219.841698      1  37.531590  127.066720     이튼타워리버5차        서울시 광진구 자양동   아파트   True\n",
       "4  37.502964  126.856017  16  2024    7   12  1999.0    2.0   24.0  987  13  25.382615    943.409092      1  37.494698  126.858504         고척대우        서울시 구로구 고척동   아파트  False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import joblib\n",
    "# Display the dataframe with predictions\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "preprocessor = joblib.load('feature_preprocessor.pkl')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model(\"xgboost_model.json\")\n",
    "\n",
    "# Define the features\n",
    "numeric_features = ['위도', '경도', '층', '거래연', '거래월', '거래일', '사용승인연', '사용승인월', '사용승인일', '가구수', '동수', '나이', '역과거리', '근접노선수', '역lati', '역longi']\n",
    "categorical_features = ['아파트명', '동네', '건물종류', '도보거리']\n",
    "features = numeric_features + categorical_features\n",
    "\n",
    "# Load or prepare df_final\n",
    "# Assuming df_final is already loaded and processed\n",
    "# df_final should have columns matching the features list\n",
    "# Ensure df_final contains only the relevant features\n",
    "df_final = df_final[features]\n",
    "display(df_final.head())\n",
    "# ColumnTransformer for preprocessing\n",
    "# numeric_transformer = StandardScaler()\n",
    "# categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numeric_transformer, numeric_features),\n",
    "#         ('cat', categorical_transformer, categorical_features)\n",
    "#     ])\n",
    "\n",
    "# Fit the preprocessor on the entire dataset (assuming you have a training set available)\n",
    "# Here you should fit the preprocessor on the same data you used for training the model.\n",
    "# For demonstration, we're fitting it on df_final.\n",
    "# X_transformed = preprocessor.fit_transform(df_final)\n",
    "X_transformed = preprocessor.transform(df_final)\n",
    "\n",
    "\n",
    "# Convert to DMatrix\n",
    "dnew = xgb.DMatrix(X_transformed)\n",
    "\n",
    "# Predict\n",
    "predictions = loaded_model.predict(dnew)\n",
    "\n",
    "# Optionally, you can add the predictions to the dataframe\n",
    "df_final['Predictions'] = predictions\n",
    "\n",
    "# Merge predictions with df_merged if necessary\n",
    "# Ensure df_merged is properly loaded and available in your context\n",
    "df_merged = df_merged.join(df_final[['거래연', '거래월', '거래일', '사용승인연', '사용승인월', '사용승인일', 'Predictions']], how='left')\n",
    "\n",
    "\n",
    "# Print or return the merged dataframe with predictions\n",
    "# print(df_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2210, 40)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_dataframe_into_table(df_merged, 'clbe_customer_realestate_model', if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
